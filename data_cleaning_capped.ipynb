{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "dc66e3ed-406c-4d13-8ce1-cb7bfe032ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow as pa\n",
    "import os\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee219c6a-0a29-457e-a0bc-df9666b537c2",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c2cafe89-8d8f-4ce8-ad55-1ddb0e6ebeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zs/0gklbd017c758v1gqchfcyk00000gn/T/ipykernel_1775/849930714.py:8: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ridership_df = pd.read_csv(csv2_path, nrows=30000000)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "survey_df: (13866, 8)\n",
      "ridership_df: (7879638, 17)\n",
      "arrival_departure_df: (30000000, 14)\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "csv1_path = \"./Data/MBTA_2024_System-Wide_Passenger_Survey.csv\"\n",
    "parquet_path = \"./Data/mbta_arrival_departure_merged_direction.parquet\"\n",
    "csv2_path = \"./Data/MBTA_Bus_Ridership_2016-2024.csv\"\n",
    "\n",
    "# Loading\n",
    "survey_df = pd.read_csv(csv1_path, nrows=30000000)\n",
    "ridership_df = pd.read_csv(csv2_path, nrows=30000000)\n",
    "\n",
    "# For Parquet\n",
    "arrival_departure_df = pd.read_parquet(parquet_path, dtype_backend=\"pyarrow\").head(30000000)\n",
    "\n",
    "print(\"survey_df:\", survey_df.shape)\n",
    "print(\"ridership_df:\", ridership_df.shape)\n",
    "print(\"arrival_departure_df:\", arrival_departure_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "307e44be-6357-43e9-a740-5eced2f9806b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aggregation_level</th>\n",
       "      <th>service_mode</th>\n",
       "      <th>reporting_group</th>\n",
       "      <th>measure_group</th>\n",
       "      <th>measure</th>\n",
       "      <th>category</th>\n",
       "      <th>weighted_percent</th>\n",
       "      <th>ObjectId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reporting Group</td>\n",
       "      <td>Bus</td>\n",
       "      <td>10</td>\n",
       "      <td>Alternative Modes</td>\n",
       "      <td>Alternative Mode</td>\n",
       "      <td>Drive or Ride in a Carpool</td>\n",
       "      <td>0.316855</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Reporting Group</td>\n",
       "      <td>Bus</td>\n",
       "      <td>10</td>\n",
       "      <td>Alternative Modes</td>\n",
       "      <td>Alternative Mode</td>\n",
       "      <td>Bike, Scooter, or Other Micromobility</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reporting Group</td>\n",
       "      <td>Bus</td>\n",
       "      <td>10</td>\n",
       "      <td>Alternative Modes</td>\n",
       "      <td>Alternative Mode</td>\n",
       "      <td>Private Shuttle or Other Transit</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Reporting Group</td>\n",
       "      <td>Bus</td>\n",
       "      <td>10</td>\n",
       "      <td>Alternative Modes</td>\n",
       "      <td>Alternative Mode</td>\n",
       "      <td>Other</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reporting Group</td>\n",
       "      <td>Bus</td>\n",
       "      <td>10</td>\n",
       "      <td>Alternative Modes</td>\n",
       "      <td>Used Alternative Mode</td>\n",
       "      <td>No</td>\n",
       "      <td>0.837547</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  aggregation_level service_mode reporting_group      measure_group  \\\n",
       "0   Reporting Group          Bus              10  Alternative Modes   \n",
       "1   Reporting Group          Bus              10  Alternative Modes   \n",
       "2   Reporting Group          Bus              10  Alternative Modes   \n",
       "3   Reporting Group          Bus              10  Alternative Modes   \n",
       "4   Reporting Group          Bus              10  Alternative Modes   \n",
       "\n",
       "                 measure                               category  \\\n",
       "0       Alternative Mode             Drive or Ride in a Carpool   \n",
       "1       Alternative Mode  Bike, Scooter, or Other Micromobility   \n",
       "2       Alternative Mode       Private Shuttle or Other Transit   \n",
       "3       Alternative Mode                                  Other   \n",
       "4  Used Alternative Mode                                     No   \n",
       "\n",
       "   weighted_percent  ObjectId  \n",
       "0          0.316855         1  \n",
       "1          0.000000         2  \n",
       "2          0.000000         3  \n",
       "3          0.000000         4  \n",
       "4          0.837547         5  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(survey_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "624c0c8f-1db5-4118-b761-b93ff296288b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>service_date</th>\n",
       "      <th>route_id</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>half_trip_id</th>\n",
       "      <th>time_point_id</th>\n",
       "      <th>time_point_order</th>\n",
       "      <th>actual</th>\n",
       "      <th>scheduled</th>\n",
       "      <th>scheduled_headway</th>\n",
       "      <th>headway</th>\n",
       "      <th>point_type</th>\n",
       "      <th>standard_type</th>\n",
       "      <th>earliness</th>\n",
       "      <th>direction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-08-01T00:00:00Z</td>\n",
       "      <td>01</td>\n",
       "      <td>75</td>\n",
       "      <td>40121394</td>\n",
       "      <td>mit</td>\n",
       "      <td>4</td>\n",
       "      <td>1900-01-01T05:19:34Z</td>\n",
       "      <td>1900-01-01T05:19:00Z</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Midpoint</td>\n",
       "      <td>Schedule</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-08-01T00:00:00Z</td>\n",
       "      <td>01</td>\n",
       "      <td>79</td>\n",
       "      <td>40121394</td>\n",
       "      <td>hynes</td>\n",
       "      <td>5</td>\n",
       "      <td>1900-01-01T05:23:20Z</td>\n",
       "      <td>1900-01-01T05:22:00Z</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Midpoint</td>\n",
       "      <td>Schedule</td>\n",
       "      <td>3.0</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-08-01T00:00:00Z</td>\n",
       "      <td>01</td>\n",
       "      <td>187</td>\n",
       "      <td>40121394</td>\n",
       "      <td>masta</td>\n",
       "      <td>6</td>\n",
       "      <td>1900-01-01T05:25:58Z</td>\n",
       "      <td>1900-01-01T05:25:00Z</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Midpoint</td>\n",
       "      <td>Schedule</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-08-01T00:00:00Z</td>\n",
       "      <td>01</td>\n",
       "      <td>59</td>\n",
       "      <td>40121394</td>\n",
       "      <td>Wasma</td>\n",
       "      <td>7</td>\n",
       "      <td>1900-01-01T05:28:26Z</td>\n",
       "      <td>1900-01-01T05:28:00Z</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Midpoint</td>\n",
       "      <td>Schedule</td>\n",
       "      <td>7.0</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-08-01T00:00:00Z</td>\n",
       "      <td>01</td>\n",
       "      <td>110</td>\n",
       "      <td>40121565</td>\n",
       "      <td>hhgat</td>\n",
       "      <td>1</td>\n",
       "      <td>1900-01-01T05:29:57Z</td>\n",
       "      <td>1900-01-01T05:30:00Z</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>Startpoint</td>\n",
       "      <td>Headway</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>inbound</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           service_date route_id  stop_id  half_trip_id time_point_id  \\\n",
       "0  2018-08-01T00:00:00Z       01       75      40121394           mit   \n",
       "1  2018-08-01T00:00:00Z       01       79      40121394         hynes   \n",
       "2  2018-08-01T00:00:00Z       01      187      40121394         masta   \n",
       "3  2018-08-01T00:00:00Z       01       59      40121394         Wasma   \n",
       "4  2018-08-01T00:00:00Z       01      110      40121565         hhgat   \n",
       "\n",
       "   time_point_order                actual             scheduled  \\\n",
       "0                 4  1900-01-01T05:19:34Z  1900-01-01T05:19:00Z   \n",
       "1                 5  1900-01-01T05:23:20Z  1900-01-01T05:22:00Z   \n",
       "2                 6  1900-01-01T05:25:58Z  1900-01-01T05:25:00Z   \n",
       "3                 7  1900-01-01T05:28:26Z  1900-01-01T05:28:00Z   \n",
       "4                 1  1900-01-01T05:29:57Z  1900-01-01T05:30:00Z   \n",
       "\n",
       "   scheduled_headway  headway  point_type standard_type  earliness direction  \n",
       "0               <NA>     <NA>    Midpoint      Schedule      -10.0   inbound  \n",
       "1               <NA>     <NA>    Midpoint      Schedule        3.0   inbound  \n",
       "2               <NA>     <NA>    Midpoint      Schedule      -33.0   inbound  \n",
       "3               <NA>     <NA>    Midpoint      Schedule        7.0   inbound  \n",
       "4             1200.0   1218.0  Startpoint       Headway       <NA>   inbound  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(arrival_departure_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "eda7fa1b-ce52-4b81-b433-d1132e26158a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alightings</th>\n",
       "      <th>boardings</th>\n",
       "      <th>day_type_id</th>\n",
       "      <th>day_type_name</th>\n",
       "      <th>direction_id</th>\n",
       "      <th>load_</th>\n",
       "      <th>route_id</th>\n",
       "      <th>route_variant</th>\n",
       "      <th>sample_size</th>\n",
       "      <th>season</th>\n",
       "      <th>stop_id</th>\n",
       "      <th>stop_name</th>\n",
       "      <th>stop_sequence</th>\n",
       "      <th>trip_start_time</th>\n",
       "      <th>source_file</th>\n",
       "      <th>term_from_name</th>\n",
       "      <th>year_from_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>day_type_01</td>\n",
       "      <td>weekday</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1</td>\n",
       "      <td>1-0-0</td>\n",
       "      <td>13</td>\n",
       "      <td>Fall 2016</td>\n",
       "      <td>1</td>\n",
       "      <td>WASHINGTON ST OPP RUGGLES ST</td>\n",
       "      <td>2</td>\n",
       "      <td>04:37:00</td>\n",
       "      <td>MBTA_Bus_Ridership_by_Trip_Season_Route_Line_a...</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>day_type_01</td>\n",
       "      <td>weekday</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1-0-0</td>\n",
       "      <td>13</td>\n",
       "      <td>Fall 2016</td>\n",
       "      <td>10003</td>\n",
       "      <td>ALBANY ST OPP RANDALL ST</td>\n",
       "      <td>5</td>\n",
       "      <td>04:37:00</td>\n",
       "      <td>MBTA_Bus_Ridership_by_Trip_Season_Route_Line_a...</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>day_type_01</td>\n",
       "      <td>weekday</td>\n",
       "      <td>0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1-0-0</td>\n",
       "      <td>13</td>\n",
       "      <td>Fall 2016</td>\n",
       "      <td>101</td>\n",
       "      <td>MASSACHUSETTS AVE @ SIDNEY ST</td>\n",
       "      <td>19</td>\n",
       "      <td>04:37:00</td>\n",
       "      <td>MBTA_Bus_Ridership_by_Trip_Season_Route_Line_a...</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>day_type_01</td>\n",
       "      <td>weekday</td>\n",
       "      <td>0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1-0-0</td>\n",
       "      <td>13</td>\n",
       "      <td>Fall 2016</td>\n",
       "      <td>102</td>\n",
       "      <td>MASSACHUSETTS AVE @ PROSPECT</td>\n",
       "      <td>20</td>\n",
       "      <td>04:37:00</td>\n",
       "      <td>MBTA_Bus_Ridership_by_Trip_Season_Route_Line_a...</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>day_type_01</td>\n",
       "      <td>weekday</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1-0-0</td>\n",
       "      <td>13</td>\n",
       "      <td>Fall 2016</td>\n",
       "      <td>104</td>\n",
       "      <td>MASSACHUSETTS AVE @ BIGELOW S</td>\n",
       "      <td>21</td>\n",
       "      <td>04:37:00</td>\n",
       "      <td>MBTA_Bus_Ridership_by_Trip_Season_Route_Line_a...</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alightings  boardings  day_type_id day_type_name  direction_id  load_  \\\n",
       "0         0.3        0.4  day_type_01       weekday             0    7.8   \n",
       "1         0.0        0.1  day_type_01       weekday             0    9.4   \n",
       "2         0.4        0.0  day_type_01       weekday             0   10.4   \n",
       "3         2.5        0.6  day_type_01       weekday             0    8.5   \n",
       "4         0.2        0.1  day_type_01       weekday             0    8.4   \n",
       "\n",
       "  route_id route_variant  sample_size     season  stop_id  \\\n",
       "0        1         1-0-0           13  Fall 2016        1   \n",
       "1        1         1-0-0           13  Fall 2016    10003   \n",
       "2        1         1-0-0           13  Fall 2016      101   \n",
       "3        1         1-0-0           13  Fall 2016      102   \n",
       "4        1         1-0-0           13  Fall 2016      104   \n",
       "\n",
       "                       stop_name  stop_sequence trip_start_time  \\\n",
       "0   WASHINGTON ST OPP RUGGLES ST              2        04:37:00   \n",
       "1       ALBANY ST OPP RANDALL ST              5        04:37:00   \n",
       "2  MASSACHUSETTS AVE @ SIDNEY ST             19        04:37:00   \n",
       "3   MASSACHUSETTS AVE @ PROSPECT             20        04:37:00   \n",
       "4  MASSACHUSETTS AVE @ BIGELOW S             21        04:37:00   \n",
       "\n",
       "                                         source_file term_from_name  \\\n",
       "0  MBTA_Bus_Ridership_by_Trip_Season_Route_Line_a...           Fall   \n",
       "1  MBTA_Bus_Ridership_by_Trip_Season_Route_Line_a...           Fall   \n",
       "2  MBTA_Bus_Ridership_by_Trip_Season_Route_Line_a...           Fall   \n",
       "3  MBTA_Bus_Ridership_by_Trip_Season_Route_Line_a...           Fall   \n",
       "4  MBTA_Bus_Ridership_by_Trip_Season_Route_Line_a...           Fall   \n",
       "\n",
       "   year_from_name  \n",
       "0            2016  \n",
       "1            2016  \n",
       "2            2016  \n",
       "3            2016  \n",
       "4            2016  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ridership_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "5067aec0-e295-4c0a-905c-a878255de3b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 10, 100, 101, 104, 105, 106, 108, 109, 11, 110, 111, 112, 114,\n",
       "       116, 117, 119, 120, 121, 131, 132, 134, 136, 137, 14, 15, 16, 17,\n",
       "       170, 171, 18, 19, 201, 202, 21, 210, 211, 212, 214, 215, 216, 217,\n",
       "       22, 220, 221, 222, 225, 23, 230, 236, 238, 24, 240, 245, 26, 27,\n",
       "       28, 29, 30, 31, 32, '32', '325', '326', '33', '34', '34E', '35',\n",
       "       '350', '352', '351', '354', '36', '37', 37, 38, 39, 4, 40, 41, 411,\n",
       "       42, 424, 426, 428, 429, 43, 430, 434, 435, 436, 439, 44, 441, 442,\n",
       "       448, 449, 45, 450, 451, 455, 456, 459, 465, 47, 5, 50, 501, 502,\n",
       "       503, 504, 505, 51, 52, 55, 553, 554, 556, 558, 57, '57', '57A',\n",
       "       '59', '60', '62', '64', '65', '66', 66, 67, 68, 69, 7, 70, '70',\n",
       "       '701', '708', '70A', '71', '72', '73', 73, 74, 741, 742, 746, 747,\n",
       "       749, 75, 751, 76, 77, 78, 79, 8, 80, 83, 84, 85, 86, 87, 88, 89, 9,\n",
       "       90, 91, 92, 93, 94, 95, 96, 97, 99, '31', 36, 65, '712', '713',\n",
       "       713, 72, 325, 326, 33, 34, 352, 350, 351, 354, 64, 71, 712, 743,\n",
       "       59, 60, 62, '725', 226, 61, 708, 35], dtype=object)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridership_df['route_id'].unique()[:200]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3580794-e23f-4609-a79b-aca03d02301f",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "c201f13d-8241-45e4-9773-8c42a8c54aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def 3normalize_route(val):\n",
    "    Normalize route IDs to comparable strings\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    s = str(val).strip().upper()\n",
    "    if s.isdigit():\n",
    "        s = s.lstrip('0') or '0'\n",
    "    return s\n",
    "\n",
    "arrival_departure_df['route_id_norm'] = arrival_departure_df['route_id'].apply(normalize_route)\n",
    "ridership_df['route_id_norm'] = ridership_df['route_id'].apply(normalize_route)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "98ea0bf1-c7ae-4947-a29b-3b0a7d0816af",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrival_departure_df['route_id'] = arrival_departure_df['route_id'].apply(normalize_route)\n",
    "survey_df['reporting_group'] = survey_df['reporting_group'].apply(normalize_route)\n",
    "ridership_df['route_id'] = ridership_df['route_id'].apply(normalize_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "13e6d541-5231-4133-8be1-3f3282e67217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routes present in both datasets:\n",
      "['1', '10', '100', '101', '104', '105', '106', '108', '109', '11', '110', '111', '112', '114', '116', '117', '119', '120', '121', '131', '132', '134', '136', '137', '14', '15', '16', '17', '170', '171', '18', '19', '201', '202', '21', '210', '211', '212', '214', '215', '216', '217', '22', '220', '221', '222', '225', '23', '230', '236', '238', '24', '240', '245', '26', '27', '28', '29', '30', '31', '32', '325', '326', '33', '34', '34E', '35', '350', '351', '352', '354', '36', '37', '38', '39', '4', '40', '41', '411', '42', '424', '426', '428', '429', '43', '430', '434', '435', '436', '439', '44', '441', '442', '448', '449', '45', '450', '451', '455', '456', '459', '465', '47', '5', '50', '501', '502', '503', '504', '505', '51', '52', '55', '553', '554', '556', '558', '57', '57A', '59', '60', '62', '64', '65', '66', '67', '68', '69', '7', '70', '70A', '71', '712', '713', '72', '73', '74', '743', '75', '76', '77', '78', '79', '8', '80', '83', '84', '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95', '96', '97', '99']\n",
      "\n",
      "Routes only in arrival_departure_df:\n",
      "['191', '192', '193', '194', '195', '6276', '7275', '746_', '9900', '9907', '9908', 'CT1', 'CT2', 'CT3', 'SL1', 'SL2', 'SL4', 'SL5']\n",
      "\n",
      " Routes only in ridership_df:\n",
      "['226', '61', '701', '708', '725', '741', '742', '746', '747', '749', '751']\n"
     ]
    }
   ],
   "source": [
    "arrival_routes = set(arrival_departure_df['route_id_norm'].dropna().unique())\n",
    "ridership_routes = set(ridership_df['route_id_norm'].dropna().unique())\n",
    "\n",
    "common_routes = sorted(arrival_routes & ridership_routes)\n",
    "only_in_arrival = sorted(arrival_routes - ridership_routes)\n",
    "only_in_ridership = sorted(ridership_routes - arrival_routes)\n",
    "\n",
    "print(\"Routes present in both datasets:\")\n",
    "print(common_routes)\n",
    "\n",
    "print(\"\\nRoutes only in arrival_departure_df:\")\n",
    "print(only_in_arrival)\n",
    "\n",
    "print(\"\\n Routes only in ridership_df:\")\n",
    "print(only_in_ridership)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b70289b-ca0d-4f3f-aa0c-bc90ee8f7340",
   "metadata": {},
   "source": [
    "### Fixing Route Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "50e5fe8d-50a2-4567-8286-26b8aeb2face",
   "metadata": {},
   "outputs": [],
   "source": [
    "arrival_departure_df['route_id'] = arrival_departure_df['route_id'].astype(str).str.strip()\n",
    "survey_df['reporting_group'] = survey_df['reporting_group'].astype(str).str.strip()\n",
    "ridership_df['route_id'] = ridership_df['route_id'].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c167b3f6-7a2b-4294-9613-7d1017599b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridership_df['route_id'] = ridership_df['route_id'].replace('746_', '746')\n",
    "arrival_departure_df['route_id'] = arrival_departure_df['route_id'].replace('746_', '746')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "41e43bc9-c8f1-4db0-8c57-57f3b3981a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any '746_' left? False\n",
      "Any '746' present? True\n"
     ]
    }
   ],
   "source": [
    "print(\"Any '746_' left?\", (ridership_df['route_id'] == '746_').any())\n",
    "print(\"Any '746' present?\", (ridership_df['route_id'] == '746').any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "4c783387-f027-4c74-b430-ea865c9a2e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any '746_' left? False\n",
      "Any '746' present? True\n"
     ]
    }
   ],
   "source": [
    "print(\"Any '746_' left?\", (arrival_departure_df['route_id'] == '746_').any())\n",
    "print(\"Any '746' present?\", (arrival_departure_df['route_id'] == '746').any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9f797c-e5a8-413d-a4b5-056942359ae5",
   "metadata": {},
   "source": [
    "### Identifying Common Bus Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "fd2dade8-39d9-4ba3-a4dd-7dd200dd5871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routes present in both (arrival_departure_df & survey_df):\n",
      "['1', '10', '104', '11', '111', '15', '16', '21', '22', '23', '32', '39', '47', '57', '66', '71', '73', '86', '9', 'SL1', 'SL2', 'SL4']\n",
      "\n",
      " Routes only in arrival_departure_df:\n",
      "['100', '101', '105', '106', '108', '109', '110', '112', '114', '116', '117', '119', '120', '121', '131', '132', '134', '136', '137', '14', '17', '170', '171', '18', '19', '191', '192', '193', '194', '195', '201', '202', '210', '211', '212', '214', '215', '216', '217', '220', '221', '222', '225', '230', '236', '238', '24', '240', '245', '26', '27', '28', '29', '30', '31', '325', '326', '33', '34', '34E', '35', '350', '351', '352', '354', '36', '37', '38', '4', '40', '41', '411', '42', '424', '426', '428', '429', '43', '430', '434', '435', '436', '439', '44', '441', '442', '448', '449', '45', '450', '451', '455', '456', '459', '465', '5', '50', '501', '502', '503', '504', '505', '51', '52', '55', '553', '554', '556', '558', '57A', '59', '60', '62', '6276', '64', '65', '67', '68', '69', '7', '70', '70A', '712', '713', '72', '7275', '74', '743', '746', '75', '76', '77', '78', '79', '8', '80', '83', '84', '85', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '99', '9900', '9907', '9908', 'CT1', 'CT2', 'CT3', 'SL5']\n",
      "\n",
      " Routes only in survey_df:\n",
      "['114, 116, & 117', '28 & 29', '34 & 34E', '4 & 7', '43 & SL5', '61 & 70', '67 & 77', '8, 55 & CT3', 'AIRPORT', 'ALEWIFE', 'ALL BLUE LINE', 'ALL BUS', 'ALL COMMUTER RAIL', 'ALL FERRY', 'ALL GREEN LINE', 'ALL MATTAPAN TROLLEY', 'ALL ORANGE LINE', 'ALL RAPID TRANSIT OR BUS RAPID TRANSIT', 'ALL RED LINE', 'ALL SILVER LINE BRT', \"AMORY STREET TO PACKARD'S CORNER\", 'ANDREW', 'AQUARIUM', 'ARLINGTON', 'ASHMONT', 'ASSEMBLY', 'BACK BAY', 'BLANDFORD STREET TO BU CENTRAL', 'BOWDOIN', 'BOYLSTON', 'BRAINTREE', 'BRIGHAM CIRCLE TO HEATH STREET', 'BRIGHTON/ALLSTON/WATERTOWN - BOSTON', 'BRIGHTON/ALLSTON/WATERTOWN - OTHER SUBURB', 'BROADWAY', 'BROOKLINE VILLAGE TO BEACONSFIELD', 'CAMBRIDGE/ARLINGTON - ALEWIFE', 'CAMBRIDGE/ARLINGTON - HARVARD', 'CENTRAL', 'CHARLES/MGH', 'CHELSEA/EAST BOSTON/LYNN/REVERE - CORE', 'CHELSEA/EAST BOSTON/LYNN/REVERE - NORTH SHORE', 'CHINATOWN', 'COMMUNITY COLLEGE', 'COOLIDGE CORNER', 'COPLEY', 'DAVIS', 'DOWNTOWN CROSSING', 'EAST SOMERVILLE AND GILMAN SQUARE', 'ELIOT TO WOODLAND', 'FAIRMOUNT LINE', 'FENWAY AND LONGWOOD', 'FERRY', 'FIELDS CORNER', 'FITCHBURG LINE', 'FOREST HILLS', 'FRAMINGHAM/WORCESTER LINE', 'FRANKLIN/FOXBORO LINE', 'GOVERNMENT CENTER', 'GREEN STREET', 'GREENBUSH LINE', 'GRIGGS STREET AND ALLSTON STREET', 'HARVARD', 'HARVARD AVE', 'HAVERHILL LINE', 'HAYMARKET', 'HYNES CONVENTION CENTER', 'JACKSON SQUARE', 'JAMAICA PLAIN/ROSLINDALE/HYDE PARK', 'JFK/UMASS', 'KENDALL/MIT', 'KENMORE', 'KINGSTON LINE', 'LECHMERE AND SCIENCE PARK/WEST END', 'LOWELL LINE', 'MAGOUN SQUARE AND BALL SQUARE', 'MALDEN CENTER', 'MALDEN/EVERETT - NORTH', 'MALDEN/EVERETT - SOUTH', 'MASSACHUSETTS AVENUE', 'MATTAPAN TROLLEY', 'MAVERICK', 'MEDFORD/TUFTS', 'MIDDLEBOROUGH/LAKEVILLE LINE', 'NEEDHAM LINE', 'NEWBURYPORT/ROCKPORT LINE', 'NORTH QUINCY', 'NORTH STATION', 'NORTHEASTERN TO LONGWOOD MEDICAL AREA', 'OAK GROVE', 'ORIENT HEIGHTS', 'PARK STREET', 'PORTER', 'PROVIDENCE/STOUGHTON LINE', 'PRUDENTIAL', 'QUINCY - EAST', 'QUINCY - WEST', 'QUINCY ADAMS', 'QUINCY CENTER', 'RESERVOIR TO NEWTON HIGHLANDS', 'REVERE BEACH', 'RIVERSIDE', 'ROXBURY CROSSING', 'ROXBURY/DORCHESTER/MATTAPAN/SOUTH END & JAMAICA PLAIN/ROSLINDALE/HYDE PARK', 'ROXBURY/DORCHESTER/MATTAPAN/SOUTH END - EAST', 'ROXBURY/DORCHESTER/MATTAPAN/SOUTH END - WEST', 'RUGGLES', \"SAINT MARY'S STREET TO SAINT PAUL STREET\", 'SAVIN HILL', 'SHAWMUT', 'SL3', 'SOMERVILLE/MEDFORD/CHARLESTOWN - EAST', 'SOMERVILLE/MEDFORD/CHARLESTOWN - WEST', 'SOUTH STATION', 'STATE', 'STONY BROOK', 'SUFFOLK DOWNS AND ORIENT HEIGHTS', 'SULLIVAN SQUARE', 'SUMMIT AVE TO CLEVELAND CIRCLE', 'SUTHERLAND TO BOSTON COLLEGE', 'SYMPHONY', 'SYSTEMWIDE', 'TUFTS MEDICAL CENTER', 'UNION', 'WARREN STREET', 'WASHINGTON STREET', 'WELLINGTON', 'WOLLASTON', 'WONDERLAND', 'WOOD ISLAND']\n"
     ]
    }
   ],
   "source": [
    "# Unique sets\n",
    "arrival_routes = set(arrival_departure_df['route_id'].dropna().unique())\n",
    "survey_routes = set(survey_df['reporting_group'].dropna().unique())\n",
    "\n",
    "# Compare\n",
    "common_routes_1 = sorted(arrival_routes & survey_routes)\n",
    "only_in_arrival_1 = sorted(arrival_routes - survey_routes)\n",
    "only_in_survey_1 = sorted(survey_routes - arrival_routes)\n",
    "\n",
    "print(\"Routes present in both (arrival_departure_df & survey_df):\")\n",
    "print(common_routes_1)\n",
    "\n",
    "print(\"\\n Routes only in arrival_departure_df:\")\n",
    "print(only_in_arrival_1)\n",
    "\n",
    "print(\"\\n Routes only in survey_df:\")\n",
    "print(only_in_survey_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "f2d404cc-e88d-4d08-a838-c88a14efbf5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routes present in both (ridership_df & survey_df):\n",
      "['1', '10', '104', '11', '111', '15', '16', '21', '22', '23', '32', '39', '47', '57', '66', '71', '73', '86', '9']\n",
      "\n",
      " Routes only in ridership_df:\n",
      "['100', '101', '105', '106', '108', '109', '110', '112', '114', '116', '117', '119', '120', '121', '131', '132', '134', '136', '137', '14', '17', '170', '171', '18', '19', '201', '202', '210', '211', '212', '214', '215', '216', '217', '220', '221', '222', '225', '226', '230', '236', '238', '24', '240', '245', '26', '27', '28', '29', '30', '31', '325', '326', '33', '34', '34E', '35', '350', '351', '352', '354', '36', '37', '38', '4', '40', '41', '411', '42', '424', '426', '428', '429', '43', '430', '434', '435', '436', '439', '44', '441', '442', '448', '449', '45', '450', '451', '455', '456', '459', '465', '5', '50', '501', '502', '503', '504', '505', '51', '52', '55', '553', '554', '556', '558', '57A', '59', '60', '61', '62', '64', '65', '67', '68', '69', '7', '70', '701', '708', '70A', '712', '713', '72', '725', '74', '741', '742', '743', '746', '747', '749', '75', '751', '76', '77', '78', '79', '8', '80', '83', '84', '85', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '99']\n",
      "\n",
      " Routes only in survey_df:\n",
      "['114, 116, & 117', '28 & 29', '34 & 34E', '4 & 7', '43 & SL5', '61 & 70', '67 & 77', '8, 55 & CT3', 'AIRPORT', 'ALEWIFE', 'ALL BLUE LINE', 'ALL BUS', 'ALL COMMUTER RAIL', 'ALL FERRY', 'ALL GREEN LINE', 'ALL MATTAPAN TROLLEY', 'ALL ORANGE LINE', 'ALL RAPID TRANSIT OR BUS RAPID TRANSIT', 'ALL RED LINE', 'ALL SILVER LINE BRT', \"AMORY STREET TO PACKARD'S CORNER\", 'ANDREW', 'AQUARIUM', 'ARLINGTON', 'ASHMONT', 'ASSEMBLY', 'BACK BAY', 'BLANDFORD STREET TO BU CENTRAL', 'BOWDOIN', 'BOYLSTON', 'BRAINTREE', 'BRIGHAM CIRCLE TO HEATH STREET', 'BRIGHTON/ALLSTON/WATERTOWN - BOSTON', 'BRIGHTON/ALLSTON/WATERTOWN - OTHER SUBURB', 'BROADWAY', 'BROOKLINE VILLAGE TO BEACONSFIELD', 'CAMBRIDGE/ARLINGTON - ALEWIFE', 'CAMBRIDGE/ARLINGTON - HARVARD', 'CENTRAL', 'CHARLES/MGH', 'CHELSEA/EAST BOSTON/LYNN/REVERE - CORE', 'CHELSEA/EAST BOSTON/LYNN/REVERE - NORTH SHORE', 'CHINATOWN', 'COMMUNITY COLLEGE', 'COOLIDGE CORNER', 'COPLEY', 'DAVIS', 'DOWNTOWN CROSSING', 'EAST SOMERVILLE AND GILMAN SQUARE', 'ELIOT TO WOODLAND', 'FAIRMOUNT LINE', 'FENWAY AND LONGWOOD', 'FERRY', 'FIELDS CORNER', 'FITCHBURG LINE', 'FOREST HILLS', 'FRAMINGHAM/WORCESTER LINE', 'FRANKLIN/FOXBORO LINE', 'GOVERNMENT CENTER', 'GREEN STREET', 'GREENBUSH LINE', 'GRIGGS STREET AND ALLSTON STREET', 'HARVARD', 'HARVARD AVE', 'HAVERHILL LINE', 'HAYMARKET', 'HYNES CONVENTION CENTER', 'JACKSON SQUARE', 'JAMAICA PLAIN/ROSLINDALE/HYDE PARK', 'JFK/UMASS', 'KENDALL/MIT', 'KENMORE', 'KINGSTON LINE', 'LECHMERE AND SCIENCE PARK/WEST END', 'LOWELL LINE', 'MAGOUN SQUARE AND BALL SQUARE', 'MALDEN CENTER', 'MALDEN/EVERETT - NORTH', 'MALDEN/EVERETT - SOUTH', 'MASSACHUSETTS AVENUE', 'MATTAPAN TROLLEY', 'MAVERICK', 'MEDFORD/TUFTS', 'MIDDLEBOROUGH/LAKEVILLE LINE', 'NEEDHAM LINE', 'NEWBURYPORT/ROCKPORT LINE', 'NORTH QUINCY', 'NORTH STATION', 'NORTHEASTERN TO LONGWOOD MEDICAL AREA', 'OAK GROVE', 'ORIENT HEIGHTS', 'PARK STREET', 'PORTER', 'PROVIDENCE/STOUGHTON LINE', 'PRUDENTIAL', 'QUINCY - EAST', 'QUINCY - WEST', 'QUINCY ADAMS', 'QUINCY CENTER', 'RESERVOIR TO NEWTON HIGHLANDS', 'REVERE BEACH', 'RIVERSIDE', 'ROXBURY CROSSING', 'ROXBURY/DORCHESTER/MATTAPAN/SOUTH END & JAMAICA PLAIN/ROSLINDALE/HYDE PARK', 'ROXBURY/DORCHESTER/MATTAPAN/SOUTH END - EAST', 'ROXBURY/DORCHESTER/MATTAPAN/SOUTH END - WEST', 'RUGGLES', \"SAINT MARY'S STREET TO SAINT PAUL STREET\", 'SAVIN HILL', 'SHAWMUT', 'SL1', 'SL2', 'SL3', 'SL4', 'SOMERVILLE/MEDFORD/CHARLESTOWN - EAST', 'SOMERVILLE/MEDFORD/CHARLESTOWN - WEST', 'SOUTH STATION', 'STATE', 'STONY BROOK', 'SUFFOLK DOWNS AND ORIENT HEIGHTS', 'SULLIVAN SQUARE', 'SUMMIT AVE TO CLEVELAND CIRCLE', 'SUTHERLAND TO BOSTON COLLEGE', 'SYMPHONY', 'SYSTEMWIDE', 'TUFTS MEDICAL CENTER', 'UNION', 'WARREN STREET', 'WASHINGTON STREET', 'WELLINGTON', 'WOLLASTON', 'WONDERLAND', 'WOOD ISLAND']\n"
     ]
    }
   ],
   "source": [
    "# Unique sets\n",
    "ridership_routes = set(ridership_df['route_id'].dropna().unique())\n",
    "survey_routes = set(survey_df['reporting_group'].dropna().unique())\n",
    "\n",
    "# Compare\n",
    "common_routes_2 = sorted(ridership_routes & survey_routes)\n",
    "only_in_ridership_2 = sorted(ridership_routes - survey_routes)\n",
    "only_in_survey_2 = sorted(survey_routes - ridership_routes)\n",
    "\n",
    "print(\"Routes present in both (ridership_df & survey_df):\")\n",
    "print(common_routes_2)\n",
    "\n",
    "print(\"\\n Routes only in ridership_df:\")\n",
    "print(only_in_ridership_2)\n",
    "\n",
    "print(\"\\n Routes only in survey_df:\")\n",
    "print(only_in_survey_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dff607-185b-4caa-814b-c535d9a64d74",
   "metadata": {},
   "source": [
    "#### We see that some columns in survey_df are named in the form route_id_1& route_id_2. We adress that issue here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9ee1db87-6d5f-463c-944c-17388c8e082b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  reporting_group route_id\n",
      "0              10     [10]\n",
      "1              10     [10]\n",
      "2              10     [10]\n",
      "3              10     [10]\n",
      "4              10     [10]\n",
      "5              10     [10]\n",
      "6              10     [10]\n",
      "7              10     [10]\n",
      "8              10     [10]\n",
      "9              10     [10]\n"
     ]
    }
   ],
   "source": [
    "ROUTE_TOKEN_RE = re.compile(r'\\b(?:SL\\d+|CT\\d+|\\d+[A-Z]?)\\b', flags=re.IGNORECASE)\n",
    "\n",
    "def normalize_route(s):\n",
    "    if pd.isna(s): return None\n",
    "    s = str(s).strip().upper()\n",
    "    s = re.sub(r'[^A-Z0-9]+', '', s)\n",
    "    if not s: return None\n",
    "    if s.isdigit():\n",
    "        s = s.lstrip('0') or '0'\n",
    "    return s\n",
    "\n",
    "def extract_route_tokens(text):\n",
    "    \"\"\"Return list of normalized routes from a reporting_group string.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    s = str(text).upper()\n",
    "    tokens = ROUTE_TOKEN_RE.findall(s)\n",
    "    out = []\n",
    "    for t in tokens:\n",
    "        out.append(t.lstrip('0') if t.isdigit() else t)\n",
    "    # dedupe preserving order\n",
    "    seen, uniq = set(), []\n",
    "    for t in out:\n",
    "        if t not in seen:\n",
    "            seen.add(t)\n",
    "            uniq.append(t)\n",
    "    return uniq\n",
    "\n",
    "# Adding the new column\n",
    "survey_df['route_id'] = survey_df['reporting_group'].map(extract_route_tokens)\n",
    "\n",
    "print(survey_df[['reporting_group', 'route_id']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37298b2-7356-4f41-8ed9-58b6a99c0b39",
   "metadata": {},
   "source": [
    "#### Now we check route_ids again with our updated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "406140c9-a2bb-4491-9e30-f7d762feecc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routes present in both (arrival_departure_df & survey_df):\n",
      "['1', '10', '104', '11', '111', '114', '116', '117', '15', '16', '21', '22', '23', '28', '29', '32', '34', '34E', '39', '4', '43', '47', '55', '57', '66', '67', '7', '70', '71', '73', '77', '8', '86', '9', 'CT3', 'SL1', 'SL2', 'SL4', 'SL5']\n",
      "\n",
      "Routes only in arrival_departure_df:\n",
      "['100', '101', '105', '106', '108', '109', '110', '112', '119', '120', '121', '131', '132', '134', '136', '137', '14', '17', '170', '171', '18', '19', '191', '192', '193', '194', '195', '201', '202', '210', '211', '212', '214', '215', '216', '217', '220', '221', '222', '225', '230', '236', '238', '24', '240', '245', '26', '27', '30', '31', '325', '326', '33', '35', '350', '351', '352', '354', '36', '37', '38', '40', '41', '411', '42', '424', '426', '428', '429', '430', '434', '435', '436', '439', '44', '441', '442', '448', '449', '45', '450', '451', '455', '456', '459', '465', '5', '50', '501', '502', '503', '504', '505', '51', '52', '553', '554', '556', '558', '57A', '59', '60', '62', '6276', '64', '65', '68', '69', '70A', '712', '713', '72', '7275', '74', '743', '746', '75', '76', '78', '79', '80', '83', '84', '85', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '99', '9900', '9907', '9908', 'CT1', 'CT2']\n",
      "\n",
      "Routes only in survey_df:\n",
      "['61', 'SL3']\n"
     ]
    }
   ],
   "source": [
    "# ARRIVAL vs SURVEY \n",
    "\n",
    "arrival_routes = set(arrival_departure_df['route_id'].dropna().astype(str).unique())\n",
    "\n",
    "survey_routes = set(\n",
    "    r\n",
    "    for lst in survey_df['route_id'].dropna()\n",
    "    for r in (lst if isinstance(lst, list) else [])\n",
    ")\n",
    "\n",
    "# Compare\n",
    "common_routes_1 = sorted(arrival_routes & survey_routes)\n",
    "only_in_arrival_1 = sorted(arrival_routes - survey_routes)\n",
    "only_in_survey_1 = sorted(survey_routes - arrival_routes)\n",
    "\n",
    "print(\"Routes present in both (arrival_departure_df & survey_df):\")\n",
    "print(common_routes_1)\n",
    "\n",
    "print(\"\\nRoutes only in arrival_departure_df:\")\n",
    "print(only_in_arrival_1)\n",
    "\n",
    "print(\"\\nRoutes only in survey_df:\")\n",
    "print(only_in_survey_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "5796770b-3334-47fb-9cb9-911764acae75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routes present in both (ridership_df & survey_df):\n",
      "['1', '10', '104', '11', '111', '114', '116', '117', '15', '16', '21', '22', '23', '28', '29', '32', '34', '34E', '39', '4', '43', '47', '55', '57', '61', '66', '67', '7', '70', '71', '73', '77', '8', '86', '9']\n",
      "\n",
      "Routes only in ridership_df:\n",
      "['100', '101', '105', '106', '108', '109', '110', '112', '119', '120', '121', '131', '132', '134', '136', '137', '14', '17', '170', '171', '18', '19', '201', '202', '210', '211', '212', '214', '215', '216', '217', '220', '221', '222', '225', '226', '230', '236', '238', '24', '240', '245', '26', '27', '30', '31', '325', '326', '33', '35', '350', '351', '352', '354', '36', '37', '38', '40', '41', '411', '42', '424', '426', '428', '429', '430', '434', '435', '436', '439', '44', '441', '442', '448', '449', '45', '450', '451', '455', '456', '459', '465', '5', '50', '501', '502', '503', '504', '505', '51', '52', '553', '554', '556', '558', '57A', '59', '60', '62', '64', '65', '68', '69', '701', '708', '70A', '712', '713', '72', '725', '74', '741', '742', '743', '746', '747', '749', '75', '751', '76', '78', '79', '80', '83', '84', '85', '87', '88', '89', '90', '91', '92', '93', '94', '95', '96', '97', '99']\n",
      "\n",
      "Routes only in survey_df:\n",
      "['CT3', 'SL1', 'SL2', 'SL3', 'SL4', 'SL5']\n"
     ]
    }
   ],
   "source": [
    "# RIDERSHIP vs SURVEY \n",
    "\n",
    "ridership_routes = set(ridership_df['route_id'].dropna().astype(str).unique())\n",
    "\n",
    "survey_routes = set(\n",
    "    r\n",
    "    for lst in survey_df['route_id'].dropna()\n",
    "    for r in (lst if isinstance(lst, list) else [])\n",
    ")\n",
    "\n",
    "# Compare\n",
    "common_routes_2 = sorted(ridership_routes & survey_routes)\n",
    "only_in_ridership_2 = sorted(ridership_routes - survey_routes)\n",
    "only_in_survey_2 = sorted(survey_routes - ridership_routes)\n",
    "\n",
    "print(\"Routes present in both (ridership_df & survey_df):\")\n",
    "print(common_routes_2)\n",
    "\n",
    "print(\"\\nRoutes only in ridership_df:\")\n",
    "print(only_in_ridership_2)\n",
    "\n",
    "print(\"\\nRoutes only in survey_df:\")\n",
    "print(only_in_survey_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "608eeab0-1dac-435f-87e4-8f26d913bf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique route_ids in survey_df:\n",
      "['1', '10', '104', '11', '111', '114', '116', '117', '15', '16', '21', '22', '23', '28', '29', '32', '34', '34E', '39', '4', '43', '47', '55', '57', '61', '66', '67', '7', '70', '71', '73', '77', '8', '86', '9', 'CT3', 'SL1', 'SL2', 'SL3', 'SL4', 'SL5']\n",
      "\n",
      "Total unique routes: 41\n"
     ]
    }
   ],
   "source": [
    "unique_survey_routes = sorted(\n",
    "    {r for lst in survey_df['route_id'].dropna() for r in lst if isinstance(lst, list)}\n",
    ")\n",
    "\n",
    "print(\"Unique route_ids in survey_df:\")\n",
    "print(unique_survey_routes)\n",
    "print(\"\\nTotal unique routes:\", len(unique_survey_routes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ae0f951f-2bfd-4aee-8f00-a01f7f3b2ac8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique reporting_group values in survey_df:\n",
      "10\n",
      "1\n",
      "104\n",
      "111\n",
      "11\n",
      "21\n",
      "114, 116, & 117\n",
      "15\n",
      "16\n",
      "22\n",
      "28 & 29\n",
      "23\n",
      "32\n",
      "34 & 34E\n",
      "39\n",
      "43 & SL5\n",
      "4 & 7\n",
      "47\n",
      "57\n",
      "66\n",
      "61 & 70\n",
      "67 & 77\n",
      "71\n",
      "73\n",
      "9\n",
      "86\n",
      "BRIGHTON/ALLSTON/WATERTOWN - BOSTON\n",
      "8, 55 & CT3\n",
      "BRIGHTON/ALLSTON/WATERTOWN - OTHER SUBURB\n",
      "CHELSEA/EAST BOSTON/LYNN/REVERE - CORE\n",
      "CAMBRIDGE/ARLINGTON - ALEWIFE\n",
      "CAMBRIDGE/ARLINGTON - HARVARD\n",
      "CHELSEA/EAST BOSTON/LYNN/REVERE - NORTH SHORE\n",
      "MALDEN/EVERETT - SOUTH\n",
      "MALDEN/EVERETT - NORTH\n",
      "QUINCY - EAST\n",
      "JAMAICA PLAIN/ROSLINDALE/HYDE PARK\n",
      "ROXBURY/DORCHESTER/MATTAPAN/SOUTH END - EAST\n",
      "QUINCY - WEST\n",
      "ROXBURY/DORCHESTER/MATTAPAN/SOUTH END & JAMAICA PLAIN/ROSLINDALE/HYDE PARK\n",
      "ROXBURY/DORCHESTER/MATTAPAN/SOUTH END - WEST\n",
      "SL4\n",
      "SOMERVILLE/MEDFORD/CHARLESTOWN - EAST\n",
      "FITCHBURG LINE\n",
      "SOMERVILLE/MEDFORD/CHARLESTOWN - WEST\n",
      "FAIRMOUNT LINE\n",
      "FRAMINGHAM/WORCESTER LINE\n",
      "GREENBUSH LINE\n",
      "FRANKLIN/FOXBORO LINE\n",
      "KINGSTON LINE\n",
      "HAVERHILL LINE\n",
      "NEEDHAM LINE\n",
      "NEWBURYPORT/ROCKPORT LINE\n",
      "MIDDLEBOROUGH/LAKEVILLE LINE\n",
      "LOWELL LINE\n",
      "PROVIDENCE/STOUGHTON LINE\n",
      "FERRY\n",
      "AIRPORT\n",
      "AQUARIUM\n",
      "BOWDOIN\n",
      "GOVERNMENT CENTER\n",
      "REVERE BEACH\n",
      "MAVERICK\n",
      "ORIENT HEIGHTS\n",
      "STATE\n",
      "WONDERLAND\n",
      "WOOD ISLAND\n",
      "SUFFOLK DOWNS AND ORIENT HEIGHTS\n",
      "AMORY STREET TO PACKARD'S CORNER\n",
      "BRIGHAM CIRCLE TO HEATH STREET\n",
      "BOYLSTON\n",
      "ARLINGTON\n",
      "BLANDFORD STREET TO BU CENTRAL\n",
      "BROOKLINE VILLAGE TO BEACONSFIELD\n",
      "COPLEY\n",
      "EAST SOMERVILLE AND GILMAN SQUARE\n",
      "COOLIDGE CORNER\n",
      "ELIOT TO WOODLAND\n",
      "FENWAY AND LONGWOOD\n",
      "GRIGGS STREET AND ALLSTON STREET\n",
      "HAYMARKET\n",
      "HARVARD AVE\n",
      "MAGOUN SQUARE AND BALL SQUARE\n",
      "KENMORE\n",
      "HYNES CONVENTION CENTER\n",
      "LECHMERE AND SCIENCE PARK/WEST END\n",
      "MEDFORD/TUFTS\n",
      "PRUDENTIAL\n",
      "NORTH STATION\n",
      "PARK STREET\n",
      "NORTHEASTERN TO LONGWOOD MEDICAL AREA\n",
      "SUMMIT AVE TO CLEVELAND CIRCLE\n",
      "SAINT MARY'S STREET TO SAINT PAUL STREET\n",
      "RIVERSIDE\n",
      "RESERVOIR TO NEWTON HIGHLANDS\n",
      "SUTHERLAND TO BOSTON COLLEGE\n",
      "SYMPHONY\n",
      "WASHINGTON STREET\n",
      "UNION\n",
      "WARREN STREET\n",
      "MATTAPAN TROLLEY\n",
      "CHINATOWN\n",
      "ASSEMBLY\n",
      "COMMUNITY COLLEGE\n",
      "BACK BAY\n",
      "FOREST HILLS\n",
      "GREEN STREET\n",
      "DOWNTOWN CROSSING\n",
      "JACKSON SQUARE\n",
      "MALDEN CENTER\n",
      "MASSACHUSETTS AVENUE\n",
      "OAK GROVE\n",
      "RUGGLES\n",
      "STONY BROOK\n",
      "ROXBURY CROSSING\n",
      "SULLIVAN SQUARE\n",
      "ALEWIFE\n",
      "WELLINGTON\n",
      "TUFTS MEDICAL CENTER\n",
      "ANDREW\n",
      "ASHMONT\n",
      "BRAINTREE\n",
      "BROADWAY\n",
      "CENTRAL\n",
      "CHARLES/MGH\n",
      "FIELDS CORNER\n",
      "DAVIS\n",
      "HARVARD\n",
      "JFK/UMASS\n",
      "KENDALL/MIT\n",
      "NORTH QUINCY\n",
      "PORTER\n",
      "QUINCY CENTER\n",
      "QUINCY ADAMS\n",
      "SHAWMUT\n",
      "SAVIN HILL\n",
      "SOUTH STATION\n",
      "WOLLASTON\n",
      "SL1\n",
      "SL2\n",
      "SL3\n",
      "ALL GREEN LINE\n",
      "ALL MATTAPAN TROLLEY\n",
      "ALL BLUE LINE\n",
      "ALL ORANGE LINE\n",
      "ALL SILVER LINE BRT\n",
      "ALL BUS\n",
      "ALL COMMUTER RAIL\n",
      "ALL RED LINE\n",
      "ALL FERRY\n",
      "ALL RAPID TRANSIT OR BUS RAPID TRANSIT\n",
      "SYSTEMWIDE\n",
      "\n",
      "Total unique reporting_groups: 152\n"
     ]
    }
   ],
   "source": [
    "# Show all unique reporting_group entries\n",
    "unique_reporting_groups = survey_df['reporting_group'].dropna().unique()\n",
    "\n",
    "print(\"Unique reporting_group values in survey_df:\")\n",
    "for val in unique_reporting_groups:\n",
    "    print(val)\n",
    "\n",
    "print(\"\\nTotal unique reporting_groups:\", len(unique_reporting_groups))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee0bff0-e61e-43c4-a2a2-d59879268c80",
   "metadata": {},
   "source": [
    "#### Dropping routes with invalid bus_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "92c488dc-40f6-41d4-b1ee-ffdd924a282c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned survey_df — only rows with valid route IDs remain.\n",
      "Remaining rows: 2685\n",
      "Unique reporting_groups after cleaning: 31\n"
     ]
    }
   ],
   "source": [
    "# Drop survey rows that have no route tokens\n",
    "survey_df = survey_df[survey_df['route_id'].map(len) > 0].reset_index(drop=True)\n",
    "\n",
    "print(\"Cleaned survey_df — only rows with valid route IDs remain.\")\n",
    "print(\"Remaining rows:\", len(survey_df))\n",
    "print(\"Unique reporting_groups after cleaning:\", survey_df['reporting_group'].nunique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78f91a8-ca7a-48dc-9e38-735d5784fb70",
   "metadata": {},
   "source": [
    "### Only keeping rows with route_id present in all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4f62c787-fb3d-4b0d-8b10-3929c376ab91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of routes -> ridership: 173, arrival: 180, survey: 41\n",
      "# of common routes across all three: 34\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def normalize_route(val):\n",
    "    #Normalize route IDs to comparable strings\n",
    "    if pd.isna(val):\n",
    "        return None\n",
    "    s = str(val).strip().upper()\n",
    "    if s.isdigit():\n",
    "        s = s.lstrip('0') or '0'\n",
    "    return s\n",
    "\n",
    "def norm_list(list_val):\n",
    "    #Normalize a list of route_ids (possibly None/NaN)\n",
    "    if not isinstance(list_val, list):\n",
    "        return []\n",
    "    out = []\n",
    "    for v in list_val:\n",
    "        nv = normalize_route(v)\n",
    "        if nv is not None:\n",
    "            out.append(nv)\n",
    "    return out\n",
    "\n",
    "#  Normalize columns\n",
    "ridership_df = ridership_df.assign(\n",
    "    route_id_norm=ridership_df['route_id'].apply(normalize_route)\n",
    ")\n",
    "\n",
    "arrival_departure_df = arrival_departure_df.assign(\n",
    "    route_id_norm=arrival_departure_df['route_id'].apply(normalize_route)\n",
    ")\n",
    "\n",
    "# For survey, the route_id column holds lists; make a normalized companion list column\n",
    "# and also build the unique set from those lists\n",
    "survey_df = survey_df.assign(\n",
    "    route_id_list_norm=survey_df['route_id'].apply(norm_list)\n",
    ")\n",
    "\n",
    "unique_survey_routes = set()\n",
    "for lst in survey_df['route_id_list_norm']:\n",
    "    unique_survey_routes.update(lst)\n",
    "\n",
    "# Build intersections \n",
    "ridership_routes = set(r for r in ridership_df['route_id_norm'].dropna().unique())\n",
    "arrival_routes   = set(r for r in arrival_departure_df['route_id_norm'].dropna().unique())\n",
    "survey_routes    = unique_survey_routes\n",
    "\n",
    "common_routes = ridership_routes & arrival_routes & survey_routes\n",
    "\n",
    "print(f\"# of routes -> ridership: {len(ridership_routes)}, arrival: {len(arrival_routes)}, survey: {len(survey_routes)}\")\n",
    "print(f\"# of common routes across all three: {len(common_routes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "11a5354f-0485-4e83-b9b1-68ba8bcfdac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will materialize -> arrival: 12,682,058; ridership: 3,327,451; survey: 2,335\n",
      "Saved capped outputs to ./data_cleaned/: arrival_departure.parquet, ridership.csv, survey.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#  caps\n",
    "ARRIVAL_MAX   = 30000000\n",
    "RIDERSHIP_MAX = 30000000\n",
    "SURVEY_MAX    = 30000000  \n",
    "\n",
    "# NumPy-only slicer\n",
    "def numpy_slice_frame(df: pd.DataFrame, idx: np.ndarray) -> pd.DataFrame:\n",
    "    out = {}\n",
    "    for c in df.columns:\n",
    "        col_np = df[c].to_numpy()\n",
    "        out[c] = np.take(col_np, idx, axis=0)\n",
    "    return pd.DataFrame(out)\n",
    "\n",
    "# build indices of matching rows \n",
    "arr_route_np = arrival_departure_df[\"route_id_norm\"].astype(\"string[python]\").to_numpy()\n",
    "rid_route_np = ridership_df[\"route_id_norm\"].astype(\"string[python]\").to_numpy()\n",
    "\n",
    "mask_arr = np.fromiter((r in common_routes for r in arr_route_np), count=arr_route_np.size, dtype=bool)\n",
    "mask_rid = np.fromiter((r in common_routes for r in rid_route_np), count=rid_route_np.size, dtype=bool)\n",
    "\n",
    "idx_arr_all = np.flatnonzero(mask_arr)\n",
    "idx_rid_all = np.flatnonzero(mask_rid)\n",
    "\n",
    "# apply caps before slicing \n",
    "idx_arr = idx_arr_all[:ARRIVAL_MAX]\n",
    "idx_rid = idx_rid_all[:RIDERSHIP_MAX]\n",
    "\n",
    "# survey: keep row if ANY route in its list is in common_routes\n",
    "svy_lists = survey_df[\"route_id_list_norm\"].to_numpy(object)\n",
    "mask_svy = np.fromiter((bool(L) and any(r in common_routes for r in L) for L in svy_lists),\n",
    "                       count=svy_lists.size, dtype=bool)\n",
    "idx_svy_all = np.flatnonzero(mask_svy)\n",
    "idx_svy = idx_svy_all[:SURVEY_MAX]\n",
    "\n",
    "print(f\"Will materialize -> arrival: {idx_arr.size:,}; ridership: {idx_rid.size:,}; survey: {idx_svy.size:,}\")\n",
    "\n",
    "arrival_df   = numpy_slice_frame(arrival_departure_df, idx_arr)\n",
    "ridership_ok = numpy_slice_frame(ridership_df, idx_rid)\n",
    "survey_ok    = numpy_slice_frame(survey_df, idx_svy)\n",
    "\n",
    "for _df, cols in [\n",
    "    (arrival_df,   [\"route_id_norm\"]),\n",
    "    (ridership_ok, [\"route_id_norm\"]),\n",
    "    (survey_ok,    [\"route_id_list_norm\"]),\n",
    "]:\n",
    "    drop_cols = [c for c in cols if c in _df.columns]\n",
    "    if drop_cols:\n",
    "        _df.drop(columns=drop_cols, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# save \n",
    "os.makedirs(\"./data_cleaned_capped\", exist_ok=True)\n",
    "\n",
    "arrival_df.to_parquet(\"./data_cleaned_capped/arrival_departure.parquet\")\n",
    "\n",
    "def write_csv_in_chunks(df: pd.DataFrame, path: str, chunksize: int = 50_000):\n",
    "    first = True\n",
    "    n = len(df)\n",
    "    for start in range(0, n, chunksize):\n",
    "        end = min(start + chunksize, n)\n",
    "        block_idx = np.arange(start, end, dtype=np.int64)\n",
    "        block = numpy_slice_frame(df, block_idx)\n",
    "        block.to_csv(path, index=False, mode=(\"w\" if first else \"a\"), header=first)\n",
    "        first = False\n",
    "\n",
    "write_csv_in_chunks(ridership_ok, \"./data_cleaned_capped/ridership.csv\", chunksize=10_000)\n",
    "write_csv_in_chunks(survey_ok,    \"./data_cleaned_capped/survey.csv\",    chunksize=10_000)\n",
    "\n",
    "print(\"Saved capped outputs to ./data_cleaned/: arrival_departure.parquet, ridership.csv, survey.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
